{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intro\n",
        "\n",
        "![Machine Learning](https://imgs.xkcd.com/comics/machine_learning.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-VIf5URNM7q"
      },
      "source": [
        "# Setup\n",
        "\n",
        "I stole this from an example, we don't need all this complexity. But I think it's cool to see.\n",
        "\n",
        "Moreover, most of my python / jupyter / colab knowledge is copied from a bunch of examples. See [Sources](#Sources).\n",
        "\n",
        "To open this in Google Colab, click [here](https://colab.research.google.com/github/klao/t9r-class/blob/master/htt_clean.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isiMrnRaOSik",
        "outputId": "d925b5c0-2863-45ca-a0a5-16e8eefae8c4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    %pip install einops\n",
        "    %pip install jaxtyping\n",
        "    %pip install transformer_lens\n",
        "    %pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "else:\n",
        "    # See README.md for local setup\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHL1yEOAPu3v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import plotly.express as px\n",
        "import torch as t\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from jaxtyping import Int, Float\n",
        "from typing import List, Optional, Tuple\n",
        "import functools\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "import webbrowser\n",
        "import gdown\n",
        "from transformer_lens.hook_points import HookPoint\n",
        "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "from transformer_lens.utils import get_corner\n",
        "import circuitsvis as cv\n",
        "\n",
        "# Saves computation time, since we don't need it for the contents of this notebook\n",
        "t.set_grad_enabled(False)\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTw0C8JsQNzi"
      },
      "source": [
        "# Getting acquainted with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAjxyDmVCVbh",
        "outputId": "6e8de37d-34b3-4ff3-90c6-27063f4a6fa8"
      },
      "outputs": [],
      "source": [
        "gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usYlUFIoQt0T"
      },
      "source": [
        "## Input: \"What does this eat?\" aka Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt2.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = (\"This is a story about Quomatarus.\"\n",
        "  + \" When one day Quomatarus decided to do something different and bought a plane ticket to Lamanandu.\"\n",
        "  + \" When he arrived to the airport Quomatarus noticed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens = gpt2.to_tokens(text)\n",
        "str_tokens = gpt2.to_str_tokens(text)\n",
        "print(str_tokens)\n",
        "print(tokens.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QFdOM1F99Ey"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt2.W_E.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYPPZ_6q-3K5"
      },
      "source": [
        "## Output: \"What comes out?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3F7o1W9-9Fm",
        "outputId": "5a51b93d-5ee2-4456-e8cc-e4f6a1777406"
      },
      "outputs": [],
      "source": [
        "print(gpt2(tokens).shape)\n",
        "print(gpt2(tokens, return_type=\"loss\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUrk3ocP_Oit",
        "outputId": "87d79e03-9ca3-4dd3-ab96-ea71c43d58d8"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# logits, cache = gpt2.run_with_cache(tokens, remove_batch_dim=True)\n",
        "logits, cache = gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)\n",
        "print(cache)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logits? Probabilities?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next token?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How well did it predict the actual tokens?\n",
        "# Log probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot it! Which tokens did it do well on? Which poorly? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9NeGFPUEO6W"
      },
      "source": [
        "# Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What do the \"big brothers\" look like?\n",
        "\n",
        "- GPT-3: https://arxiv.org/abs/2005.14165v4\n",
        "- PaLM: https://jmlr.org/papers/v24/22-1144.html\n",
        "- LLaMA: https://arxiv.org/abs/2302.13971"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, p in gpt2.named_parameters():\n",
        "  if \".0.\" in name or \"blocks\" not in name:\n",
        "    print(name, p.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for activation_name, activation in cache.items():\n",
        "    # Only print for the first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replicate part of the code. Maybe MLP?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at attention patterns\n",
        "# cv.attention.attention_pattern(s), don't forget to squeeze!\n",
        "\n",
        "# Compare block 0 head 5 to block 5 head 5!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofmt1dRIEYzk"
      },
      "source": [
        "# Induction Heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "attention_pattern = cache[\"pattern\", 5, \"attn\"].squeeze()\n",
        "\n",
        "display(cv.attention.attention_patterns(\n",
        "    tokens=str_tokens,\n",
        "    attention=attention_pattern,\n",
        "    attention_head_names=[f\"L5H{i}\" for i in range(12)],\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coJLiIBg4FzK"
      },
      "source": [
        "# Sources\n",
        "\n",
        "These are the main inspirations:\n",
        "\n",
        "* https://arena-ch1-transformers.streamlit.app/[1.2]_Intro_to_Mech_Interp\n",
        "* https://transformer-circuits.pub/2021/framework/index.html\n",
        "\n",
        "Videos:\n",
        "\n",
        "* https://neelnanda.io/transformer-tutorial\n",
        "\n",
        "Other:\n",
        "\n",
        "* https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
